---
title: "An Introduction to mixR"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{An Introduction to mixR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
abstract: "This document provides an introduction to R Markdown, argues for its..."
keywords: "pandoc, r markdown, knitr"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width=6, 
  fig.height=4
)
```

```{r setup}
library(mixR)
```

# Background

## Mixture models

## Selecting mixture models

### Mixture model selection by information criteria

### Mixture model selection by bootstrapping likelihood ratio test

## Beyond normality

# mixR package
## Model fitting
The function `mixfit()` can be used to fit mixture models for four different families -- Normal, Weibull, Gamma, and Log-normal. For Normal distribution, we can constrain the variance of each component to be the same by setting `ev = TRUE`. The fitted results can be plotted using base R plot system or ggplot.
```{r, fig.show="hold", out.width="45%"}
set.seed(102)

# Normal (unequal variances)
x1 = rmixnormal(1000, c(0.3, 0.7), c(-2, 3), c(2, 1))
mod1 = mixfit(x1, ncomp = 2)
mod1

# Normal (equal variance)
mod1_ev = mixfit(x1, ncomp = 2, ev = TRUE)
mod1_ev

plot(mod1, breaks = 30, main = 'Normal Mixture (unequal variances)')
plot(mod1_ev, breaks = 30, main = 'Normal Mixture (equal variance)')

plot(mod1, ps = 'ggplot', breaks = 30, title = 'Normal Mixture (unequal variances)')
plot(mod1_ev, ps = 'ggplot', breaks = 30, title = 'Normal Mixture (equal variance)')
```

If users don't provide the initial values for the parameters, k-means or hierarchical clustering will be used to select initial values automatically. Most of the times this works but in cases when the algorithm is stuck in a local minimum and fitted results are visually not satisfying, which could happen when the number of components in the mixture model is relatively large and/or the data size is large, manual initial values can be provided to get a better fitting.

The initial values are provided by setting the values for all or any of `pi` (component proportions), `mu` (component means), and `sd` (component standard deviations). The initial values should be vectors of the same length as the number of components in the mixture models that we intend to fit.

As can be seen below, even though we provide different inital values, the fitted results `mod_init1`, `mod_init2` and `mod_init3` are all similar, as they are similar to `mod1` above.
```{r}
mod1_init1 = mixfit(x1, pi = c(0.5, 0.5))
mod1_init2 = mixfit(x1, pi = c(0.6, 0.4), mu = c(0, 4))
mod1_init3 = mixfit(x1, mu = c(-4, 2.5), sd = c(1.5, 1.5))

mod1_init1
mod1_init2
mod1_init3
```

Other distributions such as Weilbull, Gamma, or Log-normal might provide better fitting than Normal distribution when the actual components in the mixture model don't follow a normal distribution (e.g, when they are skewed), in which situations we can still use the normal mixture model to fit the data, but the risk is that the number of components are easily overestimated. 

To illustrate, we simulate data from a Weibull mixture model with $g = 2$, then fit the data with both Normal and Weibull mixture models with the same $g$. It is obvious that Weibull distribution provides a much better fit by plotting the fitted results, or by the fact that the log-likelihood of fitted Weibull mixture model is 474, much higher than that of the Normal mixture model (399).
```{r, fig.show="hold", out.width="45%", cache=TRUE, eval=FALSE}
x2 = rmixweibull(2000, c(0.4, 0.6), c(0.6, 1.3), c(0.1, 0.1))
mod2_weibull = mixfit(x2, family = 'weibull', ncomp = 2)
mod2_normal = mixfit(x2, ncomp = 2)

mod2_weibull

mod2_normal

plot(mod2_weibull, ps = 'ggplot')
plot(mod2_normal, ps = 'ggplot')
```

The function `select()` in the mixR package selects the best $g$ using information criteria BIC. Among the candidate models with $g$ from 2 to 6, the best Weibull mixture model has 2 components while the best Normal mixture model has 4 components with equal variance. 
```{r, fig.show="hold", out.width="45%", cache=TRUE, eval=FALSE}
# Selecting the best g when Weibull distribution is used
s_weibull = select(x2, ncomp = 2:6, family = 'weibull')
s_weibull
plot(s_weibull)

# Selecting the best g when Normal distribution is used
s = select(x2, ncomp = 2:6)
s
plot(s)

plot(mod2_weibull, ps = 'ggplot')
plot(mixfit(x2, ncomp = 4, ev = TRUE), ps = 'ggplot')
```

## Model selection
The package mixR provides two methods to compare and select $g$ for mixture models. The first method is to fit a series of candidate models first and then select the best value of $g$ with the lowest BICï¼Œwhich can be done using the function `select()` (mentioned above) . For normal mixture models, both equal and unequal variances are compared.

The second method is the bootstrap likelihood ratio test, which test a mixture model with $g = g_1$ against $g = g_2$, in which $g_1 < g_2$. The bootstrap likelihood ratio test can be done by the function `bs.test()`, which returns the p-value as well as the test statistic $w0$ and $w1$. As an example, the data set `x1` we generated above are from a Normal mixture with $g = 2$. If we test $g = 2$ against $g = 3$ for the data and set the bootstrap iterations `B=100`, we get p-value = 0.51, which means that we are not able to reject the null hypothesis (`x1` is from a Normal mixture model with `g = 2`).

As another example, the data set `x2` above are generated from a Weibull mixture model with $g = 2$. We discussed previously that if we use Normal distribution to fit the mixture model, the best value for $g$ selected by BIC is 4. A bootstrap likelihood ratio test of $g = 2$ vs $g = 4$ gives us a p-value of 0, indicating that $g = 4$ is a much better fit than $g= 2$, though visually the data shows two modes rather than four.
```{r, fig.show="hold", out.width="45%", cache=TRUE, eval=FALSE}
b1 = bs.test(x1, ncomp = c(2, 3))
str(b1)
plot(b1, main = 'Bootstrap Likelihood Ratio Test for \n Normal Mixture Models (g = 2 vs g = 3)',
     xlab = "Data")

b2 = bs.test(x2, ncomp = c(2, 4))
str(b2)
plot(b2, main = 'Bootstrap Likelihood Ratio Test for \n Normal Mixture Models  (g = 2 vs g = 4)',
     xlab = "Data")
```

## Mixture models fitted with binned data
It occurs that the data used to fit a mixture model don't have their original values available. This may happen because the mechanism that generates the data doesn't allow the original values to be collected or because of data transformation compression. Mixture models in mixR package can also be fitted to the data without original values, in the format of binned data (or grouped data). To do so we just need to provide the function `mixfit()` with the binned data, which is a three-column matrix each row of which represents a bin with left bin value, right bin values, and the total number of data points that fall in the bin (exactly the same type of data used to create a histogram). The package contains a data set `Stamp2` which is binned data. Another data set `Stamp` is the simulated original data of `Stamp2` using the function `reinstate()`.

```{r, fig.show="hold", out.width="45%", cache=TRUE, eval=FALSE}
head(Stamp)
mod_stamp = mixfit(Stamp, ncomp = 3)
mod_stamp
plot(mod_stamp, 'ggplot', title = 'Normal Mixture Model for Original Data')

head(Stamp2)
mod_stamp2 = mixfit(Stamp2, ncomp = 3)
mod_stamp2
plot(mod_stamp2, 'ggplot', title = 'Normal Mixture Model for Binned Data')
```

mixR package provides two functions: `bin()` for converting original data to binned data, and `reinstate()` for simulating the original data with binned data. As binning is actually a way to compress data, fitting mixture models on binned data can accelerate the fitting process when the original data set is large.

To illustrate, we simulate 100,000 data points from a Normal mixture model with five components, and bin the data with 100 bins. Normal mixture models are fitted on both the simulated raw data and binned data. The results show that model fitting on raw data takes 27 seconds, and on binned data it only takes 0.95 seconds. Another example shows that fitting a Weibull mixture model with four components on data binned from a raw data set with one million observations only takes 2.2 seconds!
```{r, fig.show="hold", out.width="45%", cache=TRUE, eval=FALSE}
generate_params = function(ncomp = 2) {
  pi = runif(ncomp)
  low = runif(1, 0, 0)
  upp = low + runif(1, 0, 10)
  mu = runif(ncomp, low, upp)
  sd = runif(ncomp, (max(mu) - min(mu)) / ncomp / 10, (max(mu) - min(mu)) / ncomp / 2)
  list(pi = pi / sum(pi), mu = sort(mu), sd = sd)
}

set.seed(988)
n = 100000
ncomp = 5
params = generate_params(ncomp)
x_large = rmixnormal(n, pi = params$pi, mu = params$mu, sd = params$sd)

# fitting mixture models on original data
t1 = Sys.time()
mod_large <- mixfit(x_large, ncomp = ncomp)
t2 = Sys.time()
t2 - t1

mod_large
plot(mod_large, ps = 'ggplot', title = 'Normal Mixture Model for Original Data')

# fitting mixture models on binned data
t3 = Sys.time()
x_binned = bin(x_large, seq(min(x_large), max(x_large), length = 100))
mod_binned <- mixfit(x_binned, ncomp = ncomp)
t4 = Sys.time()
t4 - t3

mod_binned
plot(mod_binned, ps = 'ggplot', title = 'Normal Mixture Model for Binned Data')
```


```{r, fig.show="hold", out.width="80%", cache=TRUE, eval=FALSE}
set.seed(247)
n = 1000000
ncomp = 4
params = generate_params(ncomp)
x_large_weibull = rmixweibull(n, pi = params$pi, mu = params$mu, sd = params$sd)
x_binned_weibull = bin(x_large_weibull, seq(min(x_large_weibull), max(x_large_weibull), length = 100))

# fitting Weibull mixture models on binned data
t5 = Sys.time()
mod_binned_weibull <- mixfit(x_binned_weibull, ncomp = ncomp, family = 'weibull')
t6 = Sys.time()
t6 - t5

mod_binned_weibull
plot(mod_binned_weibull, ps = 'ggplot', title = 'Weibull Mixture Model for Binned Data')
```
